{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOmMzoTou+E3SpcLQ26PRzI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kathushan12/Youtube-vid-analize/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup the Environment"
      ],
      "metadata": {
        "id": "OQtVk3TYn7rg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GRKY9mhfuKo"
      },
      "outputs": [],
      "source": [
        "# Huggingface & video tools\n",
        "!pip install transformers datasets\n",
        "!pip install pytube opencv-python pydub librosa --quiet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get YouTube Videos"
      ],
      "metadata": {
        "id": "RdK4iqKEoFDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import Search\n",
        "import pandas as pd\n",
        "\n",
        "def search_youtube_videos(query, max_results=5):\n",
        "    search = Search(query)\n",
        "    results = search.results[:max_results]\n",
        "\n",
        "    videos = []\n",
        "    for vid in results:\n",
        "        videos.append({\n",
        "            \"title\": vid.title,\n",
        "            \"url\": vid.watch_url\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(videos)\n",
        "\n",
        "# Example\n",
        "query = \"ai generated face\"\n",
        "video_df = search_youtube_videos(query)\n",
        "video_df\n"
      ],
      "metadata": {
        "id": "mGaCJoXTf-1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download 1 Video"
      ],
      "metadata": {
        "id": "pnsVLELSoI8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yt_dlp\n",
        "\n",
        "def download_video(url, save_path=\"/content/videos\"):\n",
        "    ydl_opts = {\n",
        "        'format': 'best',\n",
        "        'outtmpl': f'{save_path}/%(title)s.%(ext)s',\n",
        "        'quiet': True,\n",
        "    }\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        info = ydl.extract_info(url, download=True)\n",
        "        video_file_path = ydl.prepare_filename(info)\n",
        "\n",
        "    return video_file_path\n",
        "\n",
        "# Test\n",
        "os.makedirs(\"/content/videos\", exist_ok=True)\n",
        "video_path = download_video(\"https://www.youtube.com/watch?v=dQw4w9WgXcQ\")\n",
        "print(\"Downloaded video path:\", video_path)\n"
      ],
      "metadata": {
        "id": "y39VCq4IgRJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyze Video Quality using Visual Transformer"
      ],
      "metadata": {
        "id": "IjkJ4kw8oLW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "# Extract frame\n",
        "def extract_frame(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    ret, frame = cap.read()\n",
        "    cap.release()\n",
        "    if ret:\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        return Image.fromarray(frame)\n",
        "    return None\n",
        "\n",
        "frame = extract_frame(video_path)\n",
        "\n",
        "# Use Hugging Face ViT model\n",
        "image_classifier = pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\")\n",
        "image_result = image_classifier(frame)\n",
        "image_result\n"
      ],
      "metadata": {
        "id": "i4QCxSmki5tR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Audio Quality + Classification"
      ],
      "metadata": {
        "id": "8AzfJwCpoPve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "# Extract Audio\n",
        "def extract_audio(video_path, audio_path=\"/content/audio.wav\"):\n",
        "    audio = AudioSegment.from_file(video_path)\n",
        "    audio.export(audio_path, format=\"wav\")\n",
        "    return audio_path\n",
        "\n",
        "audio_path = extract_audio(video_path)\n",
        "\n",
        "# Check audio quality (RMS)\n",
        "def audio_rms(audio_path):\n",
        "    y, sr = librosa.load(audio_path)\n",
        "    return librosa.feature.rms(y=y).mean()\n",
        "\n",
        "rms_score = audio_rms(audio_path)\n",
        "print(\"Audio RMS Score:\", rms_score)\n"
      ],
      "metadata": {
        "id": "nh-2D1l-jVAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Audio Deepfake Detection"
      ],
      "metadata": {
        "id": "6XiD7V2aoS7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Wav2Vec2FeatureExtractor, AutoModelForAudioClassification\n",
        "import torchaudio\n",
        "import torch\n",
        "\n",
        "# Load correct feature extractor (NOT AutoProcessor)\n",
        "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"superb/wav2vec2-base-superb-sid\")\n",
        "model = AutoModelForAudioClassification.from_pretrained(\"superb/wav2vec2-base-superb-sid\")\n",
        "\n",
        "# Load audio\n",
        "speech_array, sampling_rate = torchaudio.load(audio_path)\n",
        "\n",
        "# Resample if needed\n",
        "if sampling_rate != 16000:\n",
        "    resampler = torchaudio.transforms.Resample(orig_freq=sampling_rate, new_freq=16000)\n",
        "    speech_array = resampler(speech_array)\n",
        "    sampling_rate = 16000\n",
        "\n",
        "# Convert to mono if stereo\n",
        "if speech_array.shape[0] > 1:\n",
        "    speech_array = torch.mean(speech_array, dim=0, keepdim=True)\n",
        "\n",
        "# Prepare input for model\n",
        "inputs = feature_extractor(speech_array.squeeze().numpy(), sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
        "\n",
        "# Predict\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs).logits\n",
        "    predicted_class_id = torch.argmax(logits).item()\n",
        "\n",
        "# Output label\n",
        "label = model.config.id2label[predicted_class_id]\n",
        "print(\"üéôÔ∏è Predicted Speaker Label:\", label)\n"
      ],
      "metadata": {
        "id": "pf1UIR6tjfg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Ranking & Display"
      ],
      "metadata": {
        "id": "K9Kx37XEoVq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = {\n",
        "    \"Title\": video_df.iloc[0][\"title\"],\n",
        "    \"Video URL\": video_df.iloc[0][\"url\"],\n",
        "    \"Visual Tags\": image_result[:2],\n",
        "    \"Audio RMS\": rms_score,\n",
        "    \"Fake Score\": predicted_class_id  # ‚úÖ FIXED here\n",
        "}\n",
        "\n",
        "pd.DataFrame([result])\n"
      ],
      "metadata": {
        "id": "s6LUsCn3l8l4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}